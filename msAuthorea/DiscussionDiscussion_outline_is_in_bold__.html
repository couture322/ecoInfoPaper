<h1 class="ltx_title_section">Discussion<br></h1><div><div><br></div><div><b>Discussion outline is in bold at the bottom of this section for reference.  </b><br></div><div><i>Outstanding questions are <b>italicized bold</b> and in parentheses.<b> </b></i><br></div><div><u>References</u> specific to the discussion are also provided at the bottom. I also left some additional content at the bottom that we could sprinkle in somewhere, and also suggest that perhaps we should add a brief&nbsp;<u>Conclusions</u> section.<br></div><div><br></div><div>Overall we documented a low rate of data recovery, with data successfully recovered from 26% of all funded projects. This rate is similar to previously published data recovery efforts (see Wollins 1962 who reported &nbsp;a 24% success rate, Wichert et al. 2006 who reported 26%, Savage &amp; Vickers 2009 who reported 10%), even though we invested considerably more effort in data recovery in terms of person hours, number of projects for which we requested data, number of contact attempts, and an electronic tracking system relative to these 3 studies (<i><b>can we say this? do the other studies list person hours?</b></i>) We should note however that although many projects comprised multiple datasets, we considered success to be the receipt of any (but not necessary all) data associated with a funded project; therefore, our estimate is conservative and likely masks a much lower recovery rate at the dataset level. In contrast to our expectations, we did not observe a greater recovery rate among more recent projects, although we did observe a statistically insignificant increase in the fraction of projects for which data recovery was successful in the two most recent years of study (<i><b>is this correct?</b></i>). Recovery rate did not vary with agency type, but did vary with research field.<br></div><div><br></div><div>We document a data recovery rate
similar to that reported by Wollins over 50 years ago [Wollins 1962], despite several important advances in the intervening time period that should have promoted and facilitated data sharing. These advances include: 1)  implementations of data sharing requirements by funding agencies and publishers; 2) the advent of a culture of open science and data sharing [Molloy 2011]; and 3) technological advances in data capture, storage (including large volume storage), accessibility, and ease of duplication and transfer (including electronic data formats and email availability). It does not appear implementation of data sharing requirements aided our recovery effort (noting that this was a requirement for all projects funded by the EVOSTC), or those data recovery efforts reported in 2006 (Wichert et al. 2006) and 2009 (Savage &amp; Vickers 2009), both of which requested data associated with publications whose journals required data sharing on request.&nbsp;It also does not appear that technology particularly aided or hindered the data recovery effort. Rather, we observed that: 1)&nbsp;only a small proportion of data we received was non-digital (4% of projects, n = 10);  2) only a small percentage of non-recoverable data fell into the 'other' category (which included obsolete technology and discarded files; 7% of projects, n = 17); and 3) we saw no difference in recovery rate between projects conducted before and after 2000 (<b>O</b><i><b>r some other way of marking the digital age?</b></i>) or between projects conducted greater than 5 years prior to our data request, both indications that advances in technology have not played an important factor.<br></div><div><br></div><div>In spite of these advances in data sharing, non-recovery of data was most commonly attributable to: 1) loss of contact with data holders (50% of projects, n = 116); 2) lack
of contact information (35% of projectes, n = 82);&nbsp;and 3( loss of data by the funding body (<i><b>X% of projects, n= X, i.e., the infamous CD</b></i>). These reasons suggest that a lack of 
foresight for long-term data archiving on the part of data PIs and funding agencies was the most important barrier to 
data sharing (<i><b>Jessica, were these reasons uniformally 
distributed across agency type and reserarch sector? If so, then we can 
say this was a universal pattern</b>).</i> This lack of foresight 
encompasses alack of planning to handle attrition of personnel 
(e.g. movement of personnel between institutions, retirement, death) and may 
also reflect an absence of adequate data curation, rendering it 
difficult and time consuming to reconstruct datasets suitable for use by others unfamiliar with the original work 
(Wichert et al. 2006, Savage &amp; Vickers 2009). The latter is 
supported by the fact that several data PIs 
(1% of projects, n = 3)<i> </i>requested funding for the time they would need  to 
format data for sharing, despite having agreed to share data upon 
acceptance of the original funding. The issue is exacerbated by a frequent lack of institutional support within government agencies that may lack  dedicated funds, and by extension personnel, for processing&nbsp;data sharing requests. &nbsp;<b>(</b><i><i><b>I feel we should take care 
not to single out our data PIs for poor data curation. This is almost 
certainly a widespread issue in ecology and it wasn't until very recently 
that people started to think about data curation for the long-term. Not 
sure how to say this?</b>)</i></i><br></div><br></div><div>There were no significant differences in data recovery rates between research sectors, but  this is likely because we lacked the statistical power to detect significant differences <i><b>(E.g. were the stats tests not significant because the equation for the test statistic is unable to find a significant difference between a category with many members (eg 120 in government) vs a category with very few members, eg 3 in tribes)? - Jessica - can you expand on this just a bit to fill in the stats? We could probably make this into its own full paragraph</b>) &nbsp;</i><br></div><div><br></div><div>We did note, however, statistically significant variation in data recovery between research fields, suggesting that the research fields of oil, physical oceanography,  plankton, and benthic invertebrates were more likely to share their data than the fields of fisheries, birds, mammals, habitat, modeling, and social studies. We expand on potential reasons why below. In general, differences in recovery rates by research field may be attributable, in part, to the time required to prepare data for sharing as well as whether or not certain data types could be misused or misinterpreted.<br></div><div><br></div><div>There are a number of reasons specific to the topics of&nbsp;oil, physical oceanography, plankton, and invertebrates which may explain why researchers in these fields are likely to share their data. Many of the oil data sets for this data salvaging project were collected by a single agency (NOAA's Auke Bay laboratory), so it was straightforward to obtain many data sets once communication with that agency was opened. Meanwhile, both physical oceanography and plankton data sets (<i><b>Gavin is it ok to remove plankton from here? plankton often require ID and enumeration under miscroscope by humanoids</b>)</i> are often collected using systematic and automated approaches. Once data are collected, they often do not require manual data entry but are already in a final format that is ready to be shared. Previous research indicates data sharing increases with the level of data collection  automation&nbsp;[Pritchard et al. 2004]. We postulate that researchers may also be likely to share benthic invertebrate data because these are collected using direct observation, and again are ready to share immediately without post-processing or fear of misinterpretation.<br></div><div><div><br></div><div>There are several reasons why researchers in fields relating to fisheries, birds, mammals, and social studies may not share their data.&nbsp;While data sharing and data recovery between scientists, stakeholders, and institutions is a challenge for many fields, the field of fisheries poses unique challenges that may also require unique solutions to overcome. Fisheries data are often sensitive in nature. They may be used for assessing vulnerable stocks that are fished by diverse groups, setting management controls such as total allowable catch limits, or monitoring the catch of sensitive or protected species. This can understandably raise concern with stakeholders who may worry that sharing their data could reveal prized fishing grounds, result in more restrictive or inequitable management, reveal illegal fishing patterns, or even lead to a fishery or particular areas being closed [Froese et al 2004; Mackinson et al 2011]. To overcome these concerns, a shared culture and strategy of collaborative research and data management should be developed between scientists, fishers, decision-makers, and other stakeholders from the onset of any new fisheries data collection program. Through this approach, shared expectations and objectives can be set such that all stakeholders understand how data will be used and how this may impact management decisions [CEC 2009; Johnson et al. 2007; Wiber et al. 2009].<br></div><br></div><div>Meanwhile, bird and mammal data sharing faces its own unique challenges. Bird data is often collected using citizen science, where the observers have varying levels of training and identification expertise [Borgman 2012]. Researchers may therefore be hesitant to share these data with a broader audience over fears of misinterpretation or misuse. <i>(<b>Jessica: were our bird data from citizen science?</b>)</i> Bird data also often includes estimates of population abundance. However, estimating population abundance could be obtained from direct or indirect observation, each of which come with certain assumptions and sampling techniques, making their integration into larger analyses non-trivial; researchers may again be concerned their studies could be misused [Baker and Millerand 2010]. Specifically for seabirds, their associated data is often complex with focuses on sitings, nesting success, and colony size. However, there is currently no recognized standard for how these data should be structured [Huettmann 2011]. Meanwhile, researchers studying marine mammals often work with small populations with limited geographic coverage, such as dolphins that may not travel widely. These researchers may be more protective over their research population since they have spent so much time and effort trying to understand it [Meyer 2009]. Additionally, for marine mammal photo ID projects, there is no common naming, format, or filing standard [Baker and Millerand 2010].<br></div><div><br></div><div><div>Finally, recovery of social science data also shares many of the same challenges as those faced with other data types, but comes with its own unique reasons why data sharing may be more limited. In particular, there may be concerns with certain types of social science data sets in which individual human subjects could be identified, which poses the risk of privacy and confidentiality violations if data are mishandled. These concerns could be mitigated, however, by protection of human subject anonymity through the deletion of identifiers,&nbsp;aggregation of data away from individuals, and privacy-enhanced data sharing protocols and intellectual property rules [Fienberg et al. 1985, Sieber 1991, King 2011].<br></div><div><br></div><div>Inherent in all of the above reasons we report for non-recovery of data is the absence of a reward structure for sharing data. There is no reward for the time investment required to: 1) learn how to curate data; or 2) reconstruct data packages where data curation was insufficient. Furthermore, once funding is delivered and once papers are published, funding agencies and journals have little power to enforce data sharing requirements. <i>(<b>some people only shared when they were seeking continuation of
funding (GWA; do we want to find a diplomatic way to say this?</b>)</i><br></div><div><br></div><div>One of our main hypotheses was that data from older projects would be less accessible [see also Michener 1997], however we found limited evidence to support this. We did not observe a gradual decrease
 in data recovery over time as expected. We did, however, observe a greater success rate in 
the most recent two years (<i><b>can you verify this Jessica?</b></i>), in general agreement with Michener's finding 
that data recovery rates decrease with time since data collection [Michener 1997]. The expected gradual decline may have been obscured because we evaluated data recovery rates based on projects instead of datasets. <b>(</b><i><b>What can we say about this, besides that we did not observe the expected temporal trend predicted by Michener? Can you guys think of reasons why we did't see it? All I can think of is that our use of project-level instead of dataset-level may have masked the expected trend?&nbsp;Were there temporal trends in reasons for non-recovery? e.g. more non-recovery in earlier years due to data loss and non-digital formats?)</b></i><br></div><div><br></div><div><u>Conclusions</u><br></div><div><i><b>We don't currently have a conclusions section, but perhaps we should add one? Otherwise, this could form the last paragraph of the discussion</b></i><br></div><div>New efforts in open science and modern technology and tools can hopefully move science forward with open data sharing . yay for data repositories (reference DataONE, etc)<br></div><div><br></div><div><u>Extra material left over - not sure if we want to sprinkle these in somewhere:</u><br></div><div>In broader terms, many of the  commonly reported reasons for not sharing data point to a high perceived risk for sharing data: <br></div><div>(i) concern about others finding errors in their results &amp; conclusions (see
speculation by all 3 other published studies), <br></div><div>(ii) retaining data ownership / authorship rights. We could cite the 2015-2016 series
of&nbsp; editorials / letters / comments in
Trends Ecol. Evol.:<br></div><div>a) Archiving
Primary Data: Solutions for Long-Term Studies <a href="http://www.cell.com/trends/ecology-evolution/fulltext/S0169-5347%2815%2900185-8"><b>http://www.cell.com/trends/ecology-evolution/fulltext/S0169-5347(15)00185-8</b></a><br></div><div>b) A Balanced Data
Archiving Policy for Long-Term Studies<br></div><div><a href="http://www.cell.com/trends/ecology-evolution/abstract/S0169-5347%2815%2900298-0"><b>http://www.cell.com/trends/ecology-evolution/abstract/S0169-5347(15)00298-0</b></a><br></div><div>c) Solutions for
Archiving Data in Long-Term Studies: A Reply to Whitlock <i><b>et
al.</b></i> <a href="http://www.cell.com/trends/ecology-evolution/abstract/S0169-5347%2815%2900301-8"><b>http://www.cell.com/trends/ecology-evolution/abstract/S0169-5347(15)00301-8</b></a><br></div><div>d) Also some food
for thought here, arising from a Jan 2016 editorial in the New England Journal
of Medicine ... especially use of the term 'research parasites': <a href="http://simplystatistics.org/2016/01/25/on-research-parasites-and-internet-mobs-lets-try-to-solve-the-real-problem/">http://simplystatistics.org/2016/01/25/on-research-parasites-and-internet-mobs-lets-try-to-solve-the-real-problem/</a><br></div><div>Notes from October 7 call - we only include data recovery efforts from defined 2 year period, even though some data and digitization has trickled in since then. Not every effort will have the luxury of continued staff time after a defined period. And this shouldn't affect analysis too much anyway, as it's a very small chunk of the recovered data.<br></div><div><br></div><div><u>References for discussion</u><br></div><br></div><ul><li><a href="http://www.vliz.be/en/imis?refid=209721">http://www.vliz.be/en/imis?refid=209721</a><br></li><li><a href="http://www.sciencedirect.com/science/article/pii/S0308597X10001375">http://www.sciencedirect.com/science/article/pii/S0308597X10001375</a><br></li><li><a href="http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=COM:2009:0163:FIN:EN:PDF">http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=COM:2009:0163:FIN:EN:PDF</a><br></li><li><a href="http://icesjms.oxfordjournals.org/content/64/4/834.short">http://icesjms.oxfordjournals.org/content/64/4/834.short</a><br></li><li><a href="http://www.sciencedirect.com/science/article/pii/S0308597X08000973">http://www.sciencedirect.com/science/article/pii/S0308597X08000973</a><br></li><li><a href="http://www.sciencedirect.com/science/article/pii/S0308597X08000973">https://books.google.com/books?hl=en&amp;lr=&amp;id=ijUrAAAAYAAJ&amp;oi=fnd&amp;pg=PR1&amp;dq=sharing+research+data+fienberg&amp;ots=bG0vHnkNzp&amp;sig=MVHLCiJJ-1BQeZ8G_TaGcvNAY70#v=onepage&amp;q=sharing%20research%20data%20fienberg&amp;f=false</a><br></li><li><a href="http://www.sciencedirect.com/science/article/pii/S0308597X08000973">https://books.google.com/books?hl=en&amp;lr=&amp;id=-O1yAwAAQBAJ&amp;oi=fnd&amp;pg=PP1&amp;dq=%22data+sharing%22+%22social+science%22&amp;ots=qSuv7t8XxK&amp;sig=WvQQt48cEB1R4xSbmGlecos2aG4#v=onepage&amp;q=%22data%20sharing%22%20%22social%20science%22&amp;f=false</a><br></li><li><a href="http://www.sciencedirect.com/science/article/pii/S0308597X08000973">http://science.sciencemag.org/content/331/6018/719.full</a><br></li><li><a href="http://onlinelibrary.wiley.com/doi/10.1002/asi.22634/full">http://onlinelibrary.wiley.com/doi/10.1002/asi.22634/full</a><br></li><li><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.466.473&amp;rep=rep1&amp;type=pdf">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.466.473&amp;rep=rep1&amp;type=pdf</a><br></li><li><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.466.473&amp;rep=rep1&amp;type=pdf">http://bentham-open.com/contents/pdf/TOOENIJ/TOOENIJ-4-1.pdf</a><br></li><li><a href="http://www.immagic.com/eLibrary/ARCHIVES/GENERAL/UCSB_US/S040823P.pdf">http://www.immagic.com/eLibrary/ARCHIVES/GENERAL/UCSB_US/S040823P.pdf</a><br></li><li>Molloy JC (2011) The Open Knowledge Foundation: Open Data Means Better Science. PLoS Biol 9(12): e1001195. doi:10.1371/journal.pbio.1001195<br></li><li><a href="http://psycnet.apa.org/doi/10.1037/0003-066X.61.7.726">http://dx.doi.org/10.1037/0003-066X.61.7.726</a><br></li><li><a href="http://dx.doi.org/10.1371/journal.pone.0007078">http://dx.doi.org/10.1371/journal.pone.0007078</a><br></li></ul><div><div><br></div><div><div><b>Discussion Outline (for reference)</b><br></div><div><b>first re-state results without going into major detail again:</b><br></div><br></div><br></div><li><div><i><b>(1) although there have been Reporting requirements in place for a while, recovery rate hasn't changed and people still don't share ...</b></i><br></div></li><ul><li><div><i><b>Publishers</b></i><br></div></li><li><div><i><b>Funders</b></i><br></div></li><li><div><b><i>...But still not happening<br></i></b><br></div></li><li><div><i><b>(2) Open science movement:</b></i><br></div></li><ul><li><div><i><b>Data sharing is important … but there are challenges</b></i><br></div></li><li><div><br></div></li></ul></ul><li><div><i><b>(3) Historical assessments of data sharing&nbsp;</b></i><br></div></li><ul><li><div><div><div><b><i>altough we didn't do a metaanalysis, recovery rates are similar to 50 yrs ago&nbsp;<br>(note I've folded this into * above</i></b><br></div><br></div><br></div></li><li><div><div><div><i><b>segue to discussion of temporal result</b></i><br></div><br></div><br></div></li></ul><div><br></div>