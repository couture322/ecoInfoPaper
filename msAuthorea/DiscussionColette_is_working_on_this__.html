<h1 class="ltx_title_section">Discussion<br></h1><div>Colette is working on this section (in progress).<br></div><div>Gavin is working on the section concerning why people do not share fisheries (done - see below).<br></div><div>Gavin is working on the section concerning why people do not share social data (done - see below)<br></div><div><br></div><div><b>NB: Discussion outline is in bold. Text inserted from first draft of discussion is in normal font. <i>Notes to you guys (or myself) are </i></b><i><b>italicized</b></i><b><i>.</i></b><br></div><div><br></div><div><br></div><div><br></div><div><i>Results:</i><br></div><div><i>we recovered data from 58% of 
physical oceanography projects, 38% of oil projects, 10% of social 
science projects, and 0% of modeling projects, these research fields had
 less than 30 projects each (Figure 2).&nbsp; 
Biological  projects were the most numerous (235), yet we only recovered
 data from 24% of those projects (Figure 2).&nbsp; To understand this 
pattern, we divided the 
biological field further and found the highest recovery rate (45%) 
for invertebrate-focused projects, and  the lowest recovery for 
habitat-focused (19%) and 
fisheries projects (20%) despite fisheries studies being the most 
numerous (n = 94).&nbsp; </i><br></div><div><br></div><div><i>the frequency of non-digital project data to be quite low (4%, n = 10) 
and not one of the main factors in our failure to recover data  (Figure 
3).&nbsp; Loss of communication was the largest hurdle to recovering data.&nbsp; 
The majority of projects for which data were not recovered became 
stalled after some initial contact with the Principal Investigators 
(PIs) had been made, but contact was ultimately lost before any data 
were recovered (50%, n = 116) (Figure 5).&nbsp; While this could have been 
because PIs had reasons they wouldn't share the data (see Disucssion), 
PIs requested funding for recovering only 1% (n = 3) of projects and 
flatly refused to share data from only 2% (n = 4) of projects.&nbsp; The 
second most common hurdle to data recovery was a lack of contact 
information for PIs or data managers, including projects entirely 
lacking contact info, as well as those with phone numbers or e-mail 
addresses from which we never received a reply (35%, n = 82)  (Figure 
3).&nbsp; Data was entirely lost from 7% (n = 17) of the projects due to 
deceased PIs, obsolete technology, and discarded files.&nbsp; Overall, the 
biggest hurdle to recovering data remains a loss of communication with 
the data producers or PIs at all stages of the recovery process</i><br></div><div><br></div><div><br></div><div><i><b>Discussion outline:</b></i><br></div><div><i><b>first re-state results without going into major detail again:</b></i><br></div><div><b>we recovered 26% of data</b><br></div><div><b>temporal: nope.</b><br></div><div><b>sectors: no diferences between agency type</b><br></div><div><b>there were differences between research fields (more data recovered from physical oceanography)</b><br></div><div>Overall we documented a low rate of data recovery: data were successfully recovered from 26% of all funded projects. Because we considered success to be the receipt of any (but potentially not all) data associated with a funded project (which often comprised multiple datasets), our estimate of 26% is conservative and likely masks a much lower recovery rate at the dataset level. In contrast to our expectations, we did not find a greater recovery rate among more recent projects, although we did observe a statistically insignificant increase in the fraction of projects for which data recovery was successful in the two most recent years of study (<i>is this correct?</i>). Recovery rate did not vary with agency type, but did vary with research field, with physical oceanography data having a much greater recovery success rate (58%) than other fields.<br></div><div><br></div><div><br></div><div><br></div><li><div><i><b>although there have been Reporting requirements in place for a while, recovery rate hasn't changed and people still don't share ...</b></i><br></div></li><ul><li><div><i><b>Publishers</b></i><br></div></li><li><div><i><b>Funders</b></i><br></div></li><li><div><b><i>...But still not happening<br><br></i></b><br></div></li></ul><div><i>I think we can roll the next 3 points (I'm numbering them </i><b><i>1-3 </i></b><i>below for clarity when we talk about this, not for the ms) into a single 'first' sentence, then branch out from there (these could probably all be a single paragraph, or more if anyone wants to expand):</i><br></div><div><div><br></div><div>We document a low data recovery rate
similar to that reported over 50 years ago (Wollins 1962), despite the advent
of several factors in the intervening time period which should have promoted and facilitated data sharing. &nbsp;We also report a similar rate to more recent reports of data recovery attempts (Wichert et al. 2006, Savage &amp; Vickers 2009; Fig.
X). <b>* </b>Although we did not perform an extensive literature search for other similar historical studies, we note the remarkable similarity(?) in data recovery rates among our study and those cited above (1962, 2006, 2009).<br></div><br></div><div><b>(1) </b>The requirement to share data did not appear to increase data recovery rates. Although data reporting requirements from funding agencies and publishers have been in place for _____ 
(how long? e.g. several decades?), our documented recovery rate was 
similar to that reported by Wollins (xx %; 1962) over 50 years ago, 
prior to the advent of data data sharing / reporting requirements. We 
also noted a 
similar success rate to that reported in 2006 (Wichert et al. 2006) and 2009 (Savage &amp; Vickers 2009), both of which requested data associated with publications whose journals required data sharing on 
request. We note that, relative to these 3 studies, we  invested considerably more effort in data recovery (with respect to person
hours, number of projects we ‘chased’, number of contact attempts, and an
electronic tracking system (ie the Redmine issues)), without noticeable
difference in recovery success.<br></div><ul><li><div><i><b>Open science movement:</b></i><br></div></li><ul><li><div><i><b>Data sharing is important … but there are challenges</b></i><br></div></li></ul><div><div><i>Not sure what we wanted to put here? </i><br></div><div><b>(2) </b>The advent of a culture of data sharing also had no apparent effect on recovery success relative to historical success rates.<br></div><br></div></ul><li><div><i><b>Historical assessments of data sharing </b></i><br></div></li><ul><li><div><div><div><b><i>altough we didn't do a metaanalysis, recovery rates are similar to 50 yrs ago (note I've put this at * above)<br></i></b><br></div><div><i>I think this can be folded into "although there have been Reporting requirements in place 
for a while, recovery rate hasn't changed and people still don't share 
... Publishers, Funders", above. </i><br></div><div><br></div><div><div><i>I also think this is a good spot to bring in that tech advances did not change recovery rates ... it fits into the historical comparison. So I'm adding that here:</i><br></div><div><br></div><div><b>(3) </b>The advent of technological advances  also appeared to have no impact on data recovery rates relative to historical success rates. Technological advances in data capture, storage (including large volume storage), accessibility,
and ease of duplication and transfer (including electronic data formats and email
availability) should have facilitated data recovery, but did not. This is supported by our observation that (i) the frequency of non-digital project data was low (4%, n = 10), 
and (ii) that non-recovery attributable to the 'other' category (deceased PIs, obsolete technology, and discarded files) was also low (7% of projects, n = 17).&nbsp;<br></div><div><br></div><div><i>merge the following into this paragraph:</i><br></div><div>Our results, combined with the similar recovery rate to the older papers, suggest that the availability of suitable digital
technology was never and is not now a factor in data recovery success. Non-recovery
attributable to factors which could have been circumvented by technological
advances – i.e. data loss (including loss of records, inability to read some hardware
or data formats like floppy disks and rare file types) and non-digital formats
(eg paper records) – accounted for only XX% (low %) of data not recovered. Notably,
X% of this data loss was attributable to loss of data by the funding body (the
infamous CD).&nbsp; Furthermore, we saw no
difference in recovery rate between projects conducted before and after 2000
(**or some other way of marking the digital age?**) – there was a similar
success rate for all projects conducted &gt;5 years prior to our data request.
Additionally, there was no difference in data recovery rate between Wollins’
study published 1962 (when recent tech was not available) and the group of
recent studies (Wichert et al. 2006, Savage &amp; Vickers 2009, and the present
study; all conducted in the age of tech advances). Collectively these results suggest
that lack of digital technology was not a factor in data recovery success.<br></div><br></div><br></div><br></div></li></ul><div>Instead, we noted variation in data recovery between research sectors, suggesting that recovery success may be related to the following: (with the caveat that perhaps we lacked statistical power to pull out significant results where we expected them, and got significant results where we had large sample sizes?)<br></div><div><br></div><div><i>from Results:</i><br></div><div><i>we recovered data from 58% of 
physical oceanography projects, 38% of oil projects, 10% of social 
science projects, and 0% of modeling projects, these research fields had
 less than 30 projects each (Figure 2).&nbsp; 
Biological  projects were the most numerous (235), yet we only recovered
 data from 24% of those projects (Figure 2).&nbsp; To understand this 
pattern, we divided the 
biological field further and found the highest recovery rate (45%) 
for invertebrate-focused projects, and  the lowest recovery for 
habitat-focused (19%) and 
fisheries projects (20%) despite fisheries studies being the most 
numerous (n = 94).</i><br></div><div><br></div><ul><li><div><i><b>Why didn’t people share their data? big section. Gavan's work here  ... (might want to restate the results just above?)</b><br></i><br></div></li></ul><div><i>There was no significant differences between fields, but is this because
we lacked the statistical power to detect significant differences? &nbsp;E.g. were the stats tests not significant
because the equation for the test statistic is unable to find a significant
difference between a category with many members (eg 120 in government) vs a
category with very few members (eg 3 in tribes)? Same situation for physical vs
biological categories. Did the new stats tests will resolve this?</i><br></div><div><br><i>Gavan, I'm pasting this paragraph here from the last draft of the discussion, as it seems it could fit in this section somewhere:</i><br>Differences in recovery rates by study category may be attributable, in part, to the time required to
prepare data for share (<i>note that the "too much work" reason for not sharing was also noted by some of our comparison studies</i>): reflected in greater success rate in perhaps
chemical (oil) and especially
physical data? Physical data often consists of automatic measurements requiring
little / no lab or digital processing (data entry) (eg temperature, salinity),
and because we measure success as some data received from a project instead of
on a dataset-by-dataset basis, this bumps up the success rate for such
projects. Conversely, categories requiring considerable processing and data
entry (e.g. social studies, which may involve transcribing human interviews,
etc) seemed to have lower data recovery rates.<i><br><br><b>&nbsp;- fisheries, birds, mammals</b><br><br><b>- social science</b><br><br><b>- takes a lot of time to make data in a publically approproate&nbsp; format retroactively (do it right the first time!)</b><br><b>&nbsp;... we expected to find a temporal trend at least in part because of this, but didn't ... see Michener too here<br><br></b></i>Specific cases in our study:<br></div><div>- lack of institutional infrastructure (i.e. lack of dedicated
money and, by extension, personnel) to handle data sharing (ADFG) ... this arises from the 'time / too much work' point above<br></div><div>- some people only shared when they were seeking continuation of
funding (GWA; find a diplomatic way to say this)<br><br></div><div>Non-recovery of data was most commonly attributable to loss of contact with data holders and lack
of contact information, suggesting that a lack of 
planning for long-term data archiving (on the part of data PIs, funding agencies, and journals) was the most important barrier to 
data sharing ... <i><b>Jessica, were these reasons uniformally distributed across agency type and reserarch sector? If so, then we can say this was a universal pattern.</b></i> This lack of planning encompasses the lack of foresight to handle attrition of personnel (movement of personnel between institutions, retirement, death) and may also reflect a lack of proper data curation right from the start, 
meaning that it's difficult and takes a lot of time for data PIs to go back and reconstruct data
 packages suitable for use by others unfamiliar with the original work. Additionally, several PIs 
requested funding to cover their time to format data for sharing, further suggesting that data had not been properly curated from the start. Wichert et al. (2006)
 and Savage &amp; Vickers (2009) also reported that this ("too 
much work") was an important reason underlying unsuccessful data recovery.&nbsp; <i>solution: data repositories are important.</i><br><br></div><div>In broader terms, the most commonly reported reasons for not sharing data,
both in our study and in the literature, point to a lack of reward structure
and high perceived risk for sharing data. Most importantly, there exists little to no reward structure for sharing data.&nbsp;Even if required by
 the original funding agency, there is no reward for this care (including learning how to curate data) and time 
investment (it takes time away from current work and doesn't get the PI 
any new grants ... caveat: unless they're applying for funding from the 
same agency). This issue is exacerbated if data are not curated properly from the start.&nbsp; <i>Now go into high perceived risk ...</i><br><br></div><br><div>- Perceived risks / disincentives: <br></div><div>(i) concern about others finding errors in their results &amp; conclusions (see
speculation by all 3 other published studies), <br></div><div>(ii) retaining data ownership / authorship rights. We could cite the 2015-2016 series
of&nbsp; editorials / letters / comments in
Trends Ecol. Evol.:<br></div><div>a) Archiving
Primary Data: Solutions for Long-Term Studies <a href="http://www.cell.com/trends/ecology-evolution/fulltext/S0169-5347%2815%2900185-8"><b>http://www.cell.com/trends/ecology-evolution/fulltext/S0169-5347(15)00185-8</b></a><br></div><div>b) A Balanced Data
Archiving Policy for Long-Term Studies<br></div><div><a href="http://www.cell.com/trends/ecology-evolution/abstract/S0169-5347%2815%2900298-0"><b>http://www.cell.com/trends/ecology-evolution/abstract/S0169-5347(15)00298-0</b></a><br></div><div>c) Solutions for
Archiving Data in Long-Term Studies: A Reply to Whitlock <i><b>et
al.</b></i> <a href="http://www.cell.com/trends/ecology-evolution/abstract/S0169-5347%2815%2900301-8"><b>http://www.cell.com/trends/ecology-evolution/abstract/S0169-5347(15)00301-8</b></a><br></div><div>d) Also some food
for thought here, arising from a Jan 2016 editorial in the New England Journal
of Medicine ... especially use of the term 'research parasites': <a href="http://simplystatistics.org/2016/01/25/on-research-parasites-and-internet-mobs-lets-try-to-solve-the-real-problem/">http://simplystatistics.org/2016/01/25/on-research-parasites-and-internet-mobs-lets-try-to-solve-the-real-problem/</a>
<br></div><div><br></div><div>In
 the discussion sections about discipline and agency categories, we can 
speculate about how some of the above reasons for not sharing data may 
underlie category differences:<br></div><div><br></div><div>Cite
 Michener et al. 1997 ... although we did not observe a gradual decrease
 in data recovery over time, we did observe a greater success rate in 
the most recent years, which generally agrees with their overall result 
that data recovery rates decrease with time since data collection. (that
 we didn't see the gradual decline may be an artifact of evaluating 
projects instead of datasets).<br></div><div><i>WERE THERE TEMPORAL TRENDS IN REASONS FOR NON-RECOVERY? EG
MORE NON-RECOVERY IN EARLIER YEARS DUE TO DATA LOSS AND NON-DIGITAL FORMATS?</i><br></div><div>... Nevertheless, this reflects an issue with long-term data
archiving permanence, and the need for foresight in data archiving.<br></div><br><div><br></div><br><div><br></div><ul><li><i><b>segue to discussion of temporal result</b></i><br></li></ul><div><br></div><div>Notes from October 7 call - we only include data recovery efforts from defined 2 year period, even though some data and digitization has trickled in since then. Not every effort will have the luxury of continued staff time after a defined period. And this shouldn't affect analysis too much anyway, as it's a very small chunk of the recovered data.<br></div><div><br></div><div>near to concluding statement:<br></div><div>though there always been reporting requirements, new efforts at open 
science and with modern technology and tools, perhaps we can move 
science foreward (hope for sharing) with open data sharing. yay for data repositories.<br></div><div><br></div><div><br></div><div><br></div><div>---------------------------------------<br></div><div><br></div><div><br></div><div><b>*This
section will need revision (or at least rearrangement) depending on how the
Introduction is structured.&nbsp; I’ll clean this up into proper sentences /
grammar and make it read better at that time!*</b><br></div><div>* In the Intro or Discussion, we should quote the text from
EVOSTC grant decisions requiring data sharing.<br></div><div>* An idea we could build on, from Wicherts et al. 2006: In
the public discourse of science, there should be a shift from [authors’
interpretation of data] to [the data themselves].<br></div><div>&nbsp;<br></div><div>Discussion text (CW):<br></div><div><br></div><div>&nbsp;<br></div><div><br></div><div><br></div><div><div>Instead,
we observed a threshold effect of time in recovery success – requests for data
collected &gt; 5 years prior to our request were markedly less successful (mean
~30% although there is a lot of variation) than requests for more recent data (mean ~ 65%? Fig. X; cite ANOVA or other stats test to say there was no effect of number of projects on success rate) <i>*although we
must decide whether to attribute this to time per se or rather personal
connections with Gulf Watch folks*</i>.<br></div><div><br></div><br></div><div><br></div><div><i>On why fisheries data recovery can be a challenge (GM):</i><br></div><div>While data sharing and data recovery between scientists, stakeholders, and institutions is a challenge for many fields, the field of fisheries poses unique challenges that may also require unique solutions to overcome. Fisheries data are often sensitive in nature. They may be used for assessing vulnerable stocks that are fished by diverse groups, setting management controls such as total allowable catch limits, or monitoring the catch of sensitive or protected species. This can understandably raise concern with stakeholders who may worry that sharing their data could reveal prized fishing grounds, result in more restrictive or inequitable management, reveal illegal fishing patterns, or even lead to a fishery or particular areas being closed [Froese et al 2004; Mackinson et al 2011]. To overcome these concerns, a shared culture and strategy of collaborative research and data management should be developed between scientists, fishers, decision-makers, and other stakeholders from the onset of any new fisheries data collection program. Through this approach, shared expectations and objectives can be set such that all stakeholders understand how data will be used and how this may impact management decisions [CEC 2009; Johnson et al. 2007; Wiber et al. 2009].<br></div><ul><li><a href="http://www.vliz.be/en/imis?refid=209721">http://www.vliz.be/en/imis?refid=209721</a><br></li><li><a href="http://www.sciencedirect.com/science/article/pii/S0308597X10001375">http://www.sciencedirect.com/science/article/pii/S0308597X10001375</a><br></li><li><a href="http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=COM:2009:0163:FIN:EN:PDF">http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=COM:2009:0163:FIN:EN:PDF</a><br></li><li><a href="http://icesjms.oxfordjournals.org/content/64/4/834.short">http://icesjms.oxfordjournals.org/content/64/4/834.short</a><br></li><li><a href="http://www.sciencedirect.com/science/article/pii/S0308597X08000973">http://www.sciencedirect.com/science/article/pii/S0308597X08000973</a><br></li></ul><div>Recovery of social science data shares many of the same challenges as those faced with other data types, but comes with its own unique reasons why data sharing may be more limited. In particular, there may be concerns with certain types of social science data sets in which individual human subjects could be identified, which poses the risk of privacy and confidentiality violations if data are mishandled. These concerns could be mitigated, however, by protection of human subject anonymity through the deletion of identifiers,&nbsp;aggregation of data away from individuals, and privacy-enhanced data sharing protocols and intellectual property rules [Fienberg et al. 1985, Sieber 1991, King 2011].<br></div><ul><li><a href="https://books.google.com/books?hl=en&amp;lr=&amp;id=ijUrAAAAYAAJ&amp;oi=fnd&amp;pg=PR1&amp;dq=sharing+research+data+fienberg&amp;ots=bG0vHnkNzp&amp;sig=MVHLCiJJ-1BQeZ8G_TaGcvNAY70#v=onepage&amp;q=sharing%20research%20data%20fienberg&amp;f=false">https://books.google.com/books?hl=en&amp;lr=&amp;id=ijUrAAAAYAAJ&amp;oi=fnd&amp;pg=PR1&amp;dq=sharing+research+data+fienberg&amp;ots=bG0vHnkNzp&amp;sig=MVHLCiJJ-1BQeZ8G_TaGcvNAY70#v=onepage&amp;q=sharing%20research%20data%20fienberg&amp;f=false</a><br></li><li><a href="https://books.google.com/books?hl=en&amp;lr=&amp;id=-O1yAwAAQBAJ&amp;oi=fnd&amp;pg=PP1&amp;dq=%22data+sharing%22+%22social+science%22&amp;ots=qSuv7t8XxK&amp;sig=WvQQt48cEB1R4xSbmGlecos2aG4#v=onepage&amp;q=%22data%20sharing%22%20%22social%20science%22&amp;f=false">https://books.google.com/books?hl=en&amp;lr=&amp;id=-O1yAwAAQBAJ&amp;oi=fnd&amp;pg=PP1&amp;dq=%22data+sharing%22+%22social+science%22&amp;ots=qSuv7t8XxK&amp;sig=WvQQt48cEB1R4xSbmGlecos2aG4#v=onepage&amp;q=%22data%20sharing%22%20%22social%20science%22&amp;f=false</a><br></li><li><a href="http://science.sciencemag.org/content/331/6018/719.full">http://science.sciencemag.org/content/331/6018/719.full</a><br></li></ul><div>Additional discussion fodder on data sharing challenges by category:<br></div><div><b><ul><li><div>Yes:<br></div></li><ul><li><div>Oil: hot topic and collected by one agency, potentially legally mandated <br></div></li><li><div>Physical: comes out of a computer, systematic, etc<br></div></li><li><div>Bio: plankton: treated like oceanography data<br></div></li><ul><li><div>Data sharing increases with level of data collection/analysis automation (could be applicable to both bio and physical) [Pritchard et al. 2004]<br></div></li><ul><li><div><a href="http://www.immagic.com/eLibrary/ARCHIVES/GENERAL/UCSB_US/S040823P.pdf">http://www.immagic.com/eLibrary/ARCHIVES/GENERAL/UCSB_US/S040823P.pdf</a><br></div></li></ul></ul><li><div>Bio: inverts: Data are ready to share once they are collected (ie. % cover)<br></div></li></ul><li><div>No:<br></div></li><ul><li><div>Fish: privacy concerns, commercial interests, data misuse<br></div></li><ul><li><div>See above writeup<br></div></li></ul><li><div>Birds: Data misuse, difficult to estimate populations from surveys<br></div></li><ul><li><div>Bird data is often collected using citizen science, where the observers have varying levels of training and identification expertise [Borgman 2012].<br></div></li><ul><li><div><a href="http://onlinelibrary.wiley.com/doi/10.1002/asi.22634/full">http://onlinelibrary.wiley.com/doi/10.1002/asi.22634/full</a><br></div></li></ul><li><div>Estimating population abundance could be obtained from direct or indirect observation, each of which come with certain assumptions and sampling techniques, making their integration non-trivial; researchers may be concerned their studies could be misused [Baker and Millerand 2010].<br></div></li><ul><li><div><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.466.473&amp;rep=rep1&amp;type=pdf">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.466.473&amp;rep=rep1&amp;type=pdf</a><br></div></li></ul><li><div>Seabird data is complex (i.e., sitings, nesting success, colony size, etc) with no recognized standard<br></div></li><ul><li><div><a href="http://bentham-open.com/contents/pdf/TOOENIJ/TOOENIJ-4-1.pdf">http://bentham-open.com/contents/pdf/TOOENIJ/TOOENIJ-4-1.pdf</a><br></div></li></ul></ul><li><div>Mammals: Data misuse, difficult to estimate populations from surveys, poaching<br></div></li><ul><li><div>Many researchers who may be working with small populations and limited geographic coverage, such as dolphins which may number in 200-500 and not travel widely, may be more protective over their research population since they have spent so much time and effort trying to understand it [Meyer 2009].<br></div></li><ul><li><div><a href="http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2166245">http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2166245</a><br></div></li></ul><li><div>For marine mammal photo ID projects, there is no common naming, format, or filing standard<br></div></li><ul><li><div><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.466.473&amp;rep=rep1&amp;type=pdf">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.466.473&amp;rep=rep1&amp;type=pdf</a><br></div></li></ul><li><div>Estimating population abundance could be obtained from direct or indirect observation, each of which come with certain assumptions and sampling techniques, making their integration non-trivial; researchers may be concerned their studies could be misused [Baker and Millerand 2010].<br></div></li><ul><li><div><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.466.473&amp;rep=rep1&amp;type=pdf">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.466.473&amp;rep=rep1&amp;type=pdf</a><br></div></li></ul></ul><li><div>Habitat: ???<br></div></li><li><div>Modeling: Less of a culture of sharing, see products as intellectual property<br></div></li><li><div>Social: data are hard to share, privacy concerns<br></div></li><ul><li><div>See above writeup<br></div></li></ul></ul></ul></b><br></div><div><br></div><div>Paragraph about results by agency
category.&nbsp; <br></div><div><i>Same comment as above.</i><br></div><div>Although recovery rates
did not differ significantly by sector (??), there was a trend towards lower
recovery rates from sectors in the public trust (Fig. X). …
<br></div><div><br></div><div><br></div><div><br></div><div><br></div><div>Must discuss implications of measuring success using project
vs dataset.<br></div><div><br></div><div>------------<br></div><div>Stuff from Results that now should be in the discussion: <br></div><div>Our data recovery success was not significantly different (p = ????, 
Figure 1) than the successes reported by three previous studies  during 
the last 55 years that tried to recover data that were supposed to be 
publicly available (ex: federal and state government data, data required
 by journals or funders to be public). &nbsp; Thus, despite technological 
advances in data collection, entry, and storage in the last half 
century, we were no more successful in recovering data than previous 
attempts.&nbsp; <br></div><div><br></div><div>We examined the amount of effort (person hours) put into data recovery,<br></div><div><br></div><div>Our data recovery took ??? person hours of effort, while previous studies had ???? hours (p = ????).&nbsp; <br></div><div><br></div><div>-------------<br></div><ul><li><div>Communication issues<br></div></li><li><div>Data archiving efforts have to have longevity - CD<br></div></li><li><div>Categories: Fish significant, etc.<br></div></li><li><div>Categories: Social significant and others<br></div></li><li><div>Sectors: the more you own the data the more likely you are to report it<br></div></li><li><div>Over time there have been about the same amount of data have been collected<br></div></li><li>Consistent recoveries between studies (since 1962) even with advances in tech<br></li></ul><div><br></div>