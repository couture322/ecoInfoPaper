<h1 class="ltx_title_section">Discussion<br></h1><div>Colette is working on this section.<br></div><div>Gavin is working on the section concerning why people do / not share data in fisheries.<br></div><div><br></div><div><b>*This
section will need revision (or at least rearrangement) depending on how the
Introduction is structured.&nbsp; I’ll clean this up into proper sentences /
grammar and make it read better at that time!*</b><br></div><div>* In the Intro or Discussion, we should quote the text from
EVOSTC grant decisions requiring data sharing.<br></div><div>* An idea we could build on, from Wicherts et al. 2006: In
the public discourse of science, there should be a shift from [authors’
interpretation of data] to [the data themselves].<br></div><div>&nbsp;<br></div><div>Discussion text (CW):<br></div><div>We document a low data recovery rate
similar to that reported over 50 years ago (Wollins 1962), despite the advent
of several factors which should promote and facilitate data sharing. &nbsp;We also report a similar rate to those
reported in 2006 and 2009 (Wichert et al. 2006, Savage &amp; Vickers 2009; Fig.
X).&nbsp; Factors which should promote and
facilitate data sharing: technological advances in data capture, storage, accessibility,
and ease of duplication (the latter including electronic format and email
availability), a shift towards a culture of data-sharing, and requirements by
journal and funding bodies for data sharing. Compared to these 3 studies in
Table X, we also invested considerably more effort in data recovery (re person
hours, number of projects we ‘chased’, number of contact attempts, and an
electronic tracking system (ie the Redmine issues)), without noticeable
difference in recovery success.<br></div><div>&nbsp;<br></div><div>Our results suggest that the <b><u>availability</u></b> of suitable digital
technology was never and is not now a factor in data recovery success. Non-recovery
attributable to factors which could have been circumvented by technological
advances – i.e. data loss (including loss of records, inability to read some hardware
or data formats like floppy disks and rare file types) and non-digital formats
(eg paper records) – accounted for only XX% (low %) of data not recovered. Notably,
X% of this data loss was attributable to loss of data by the funding body (the
infamous CD).&nbsp; Furthermore, we saw no
difference in recovery rate between projects conducted before and after 2000
(**or some other way of marking the digital age?**) – there was a similar
success rate for all projects conducted &gt;5 years prior to our data request.
Additionally, there was no difference in data recovery rate between Wollins’
study published 1962 (when recent tech was not available) and the group of
recent studies (Wichert et al. 2006, Savage &amp; Vickers 2009, and the present
study; all conducted in the age of tech advances). Collectively these results suggest
that lack of digital technology was not a factor in data recovery success.<br></div><div><br></div><div>Instead,
we observed a threshold effect of time in recovery success – requests for data
collected &gt; 5 years prior to our request were markedly less successful (mean
~30%?) than requests for more recent data (mean ~ 65%? Fig. X; cite ANOVA or other stats test to say there was no effect of number of projects on success rate) <i>*although we
must decide whether to attribute this to time per se or rather personal
connections with Gulf Watch folks*</i>. This temporal threshold, combined with the
fact that the most frequent reasons for non-recovery was loss of contact with data holders and lack
of contact information suggest that ... <br></div><div>- a lack of planning for long-term data archiving was the most important barrier to data sharing (ie lack of foresight to handle attrition of personnel: retirement, death, movement of personnel between institutions)<br></div><div>- probably also lack of proper data curation right from the start, meaning that it's difficult for data PIs to go back and reconstruct data packages suitable for use by others ... several people we contacted wanted money to cover their time to do this, and the Wichert et al. 2006 and Savage &amp; Vickers 2009 studies also reported that this ("too much work") was an important reason in their studies. &nbsp;&nbsp; <br></div><div><i>WERE THERE TEMPORAL TRENDS IN REASONS FOR NON-RECOVERY? EG
MORE NON-RECOVERY IN EARLIER YEARS DUE TO DATA LOSS AND NON-DIGITAL FORMATS?</i><br></div><div>... Nevertheless, this reflects an issue with long-term data
archiving permanence, and the need for foresight in data archiving.<br></div><div><br></div><div>Requirement to share had no effect: 2006 &amp; 2009 studies
(which requested data published by journals requiring data sharing on request),
and our study (where the funder required data sharing)<br></div><div><br></div><div><br></div><div>Why don’t people share?
Perhaps spin this as barriers to data sharing?<br></div><div>The most commonly reported reasons for not sharing data,
both in our study and in the literature, point to a lack of reward structure
and high perceived risk for sharing data:<br></div><div>- most important = no reward
structure for data sharing!!!<br></div><div>- time required to compile
data (noted as important reasons by 2/3 of our literature comparison studies)<br></div><div>- ADFG: lack of institutional infrastructure (i.e. lack of dedicated
money and, by extension, personnel) to handle data sharing<br></div><div>- GWA: only shared when they were seeking continuation of
funding (is there a diplomatic way to say this in the paper?)<br></div><div>- also very common: loss of author contact information.
Suggests that data repositories are important, or long-term foresight by
funding agencies or journals.<br></div><div>&nbsp;<br></div><div>- Perceived risks / disincentives: <br></div><div>(i) concern about others finding errors in their data (see
speculation by all 3 other published studies), <br></div><div>(ii) retaining data ownership / authorship rights. We could cite the 2015-2016 series
of&nbsp; editorials / letters / comments in
Trends Ecol. Evol.:<br></div><div>a) Archiving
Primary Data: Solutions for Long-Term Studies <a href="http://www.cell.com/trends/ecology-evolution/fulltext/S0169-5347(15)00185-8"><b>http://www.cell.com/trends/ecology-evolution/fulltext/S0169-5347(15)00185-8</b></a><br></div><div>b) A Balanced Data
Archiving Policy for Long-Term Studies<br></div><div><a href="http://www.cell.com/trends/ecology-evolution/abstract/S0169-5347(15)00298-0"><b>http://www.cell.com/trends/ecology-evolution/abstract/S0169-5347(15)00298-0</b></a><br></div><div>c) Solutions for
Archiving Data in Long-Term Studies: A Reply to Whitlock <i><b>et
al.</b></i> <a href="http://www.cell.com/trends/ecology-evolution/abstract/S0169-5347(15)00301-8"><b>http://www.cell.com/trends/ecology-evolution/abstract/S0169-5347(15)00301-8</b></a><br></div><div>d) Also some food
for thought here, arising from a Jan 2016 editorial in the New England Journal
of Medicine: <a href="http://simplystatistics.org/2016/01/25/on-research-parasites-and-internet-mobs-lets-try-to-solve-the-real-problem/">http://simplystatistics.org/2016/01/25/on-research-parasites-and-internet-mobs-lets-try-to-solve-the-real-problem/</a>
<br></div><div><br></div><div><br></div><div>Time required to
prep data package to share: reflected in greater success rate in perhaps
chemical (oil) and especially
physical data? The latter often consists of automatic measurements requiring
little / no lab or digital processing (data entry) (eg temperature, salinity),
and because we measure success as some data received from a project instead of
on a dataset-by-dataset basis, this bumps up the success rate for such
projects. Conversely, categories requiring considerable processing and data
entry (e.g. social studies, which may involve transcribing human interviews,
etc) seemed to have lower data recovery rates.<br></div><div><br></div><div>Paragraph about results by study
category. <br></div><div><i>There was no sig diff between fields, but is this because
we lacked the statistical power to detect significant differences? &nbsp;E.g. were the stats tests not significant
because the equation for the test statistic is unable to find a significant
difference between a category with many members (eg 120 in government) vs a
category with very few members (eg 3 in tribes)? Same situation for physical vs
biological categories. I’ll hold off on writing conclusions about study and
agency categories until we know.</i><br></div><div><i>* Insert Gavin's section here*</i><br></div><div>&nbsp;<br></div><div>Paragraph about results by agency
category.&nbsp; <br></div><div><i>Same comment as above.</i><br></div><div>Although recovery rates
did not differ significantly by sector (??), there was a trend towards lower
recovery rates from sectors in the public trust (Fig. X). …
<br></div><div><br></div><div>Must discuss implications of measuring success using project
vs dataset.<br></div><div><br></div><div>---<br></div><div><br></div><div><br></div><div><br></div><ul><li><div>LEAD with this: We recovered the same % of data as these other projects<br></div></li><li><div>Communication issues<br></div></li><li><div>Data archiving efforts have to have longevity - CD<br></div></li><li><div>Categories: Fish significant<br></div></li><li><div>Categories: Social significant<br></div></li><li><div>Sectors: the more you own the data the more likely you are to report it<br></div></li><li><div>Over time there have been about the same amount of data have been collected, except an uptick in recent years<br></div></li><li>Consistent recoveries between studies (since 1962) even with advances in tech<br></li></ul><div><i>On why fisheries data recovery can be a challenge (GM):</i><br></div><div>While data sharing and data recovery between scientists, stakeholders, and institutions is a challenge for many fields, the field of fisheries poses unique challenges that may also require unique solutions to overcome. Fisheries data are often sensitive in nature. They may be used for assessing vulnerable stocks that are fished by diverse groups, setting management controls such as total allowable catch limits, or monitoring the catch of sensitive or protected species. This can understandably raise concern with stakeholders who may worry that sharing their data could reveal prized fishing grounds, result in more restrictive or inequitable management, reveal illegal fishing patterns, or even lead to a fishery or particular areas being closed [Froese et al 2004; Mackinson et al 2011]. To overcome these concerns, a shared culture and strategy of collaborative research and data management  should be developed between scientists, fishers, decision-makers, and other stakeholders from the onset of any new fisheries data collection program. Through this approach, shared expectations and objectives can be set such that all stakeholders understand how data will be used and how this may impact management decisions [CEC 2009; Johnson et al. 2007; Wiber et al. 2009].<br></div><ul><li><a href="http://www.vliz.be/en/imis?refid=209721">http://www.vliz.be/en/imis?refid=209721</a><br></li><li><a href="http://www.sciencedirect.com/science/article/pii/S0308597X10001375">http://www.sciencedirect.com/science/article/pii/S0308597X10001375</a><br></li><li><a href="http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=COM:2009:0163:FIN:EN:PDF">http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=COM:2009:0163:FIN:EN:PDF</a><br></li><li><a href="http://icesjms.oxfordjournals.org/content/64/4/834.short">http://icesjms.oxfordjournals.org/content/64/4/834.short</a><br></li><li><a href="http://www.sciencedirect.com/science/article/pii/S0308597X08000973">http://www.sciencedirect.com/science/article/pii/S0308597X08000973</a><br></li></ul><div><br></div>