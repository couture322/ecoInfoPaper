<h1 class="ltx_title_section">Introduction<br></h1><div>The theory of open science is gaining popularity worldwide
but many scientists are finding actual application to be much more difficult (<u>citation</u>).
Open science refers to the public sharing of the entire scientific process from
initial brainstorm to publication and a number of tools have been developed to
facilitate openness of each of these steps, but even those deeply involved in their
development acknowledge that the movement is still in its adolescence (<u>citation</u>).
<br></div><div>&nbsp;<br></div><div>As the building block of science, data is at the crux of
opening up science, but the idea of sharing data is met with both conceptual
and practical obstacles. A long culture of perceived ownership over one’s data
combined with competition for funding and publications slows the adoption of
data sharing practices (<u>citation</u>). Scientist may fear ideas will be stolen or
publication opportunities lost if the data are published prematurely or at all.
Additionally, many of our commonly used data tools neglect to prepare data for
publication or sharing and therefore require additional training, effort and
resources to complete this extra step. While tools have been developed to help
scientists responsibly archive their data in a manner that will be accessible
and preserved through time these tools and an understanding of their
appropriate use are still sparsely available to scientists. William Michener
hypothesizes that there is a temporal trend in even the <i>knowledge</i> of one’s own data, and concludes that the older data are,
the less information exists for both the data itself and associated metadata
(Michener 1997). Given this conclusion it is realistic to assume that older the
data should the less available than newer data. Furthermore, accelerating changes
in technology should further support an increase in barriers over time, as
archiving and file formats are obsoleted. <br></div><div>&nbsp;<br></div><div>A number of studies have tested the availability of data
under open publication requirements, some dating back to the 1960s. These
studies have focused on relatively small sample sizes and data acquisition
efforts and have consistently recovered only 20-30% of the data requested
(Wolins 1962, Wicherts et al. 2006, Savage &amp; Vickers 2009, Alsheikh-Ali et
al. 2011). We wanted to test whether a larger and more modern effort would return better results than these older and
smaller studies while also documenting why data were not acquired. <br></div><div>&nbsp;<br></div><div>In 2010 the Exxon Valdez Oil Spill Trustee Council (EVOSTC)
funded the Gulf Watch Alaska group to create an open archive of the data
collected under their grants. The EVOSTC was formed following the Exxon Valdez
oil spill in the Gulf of Alaska in 1989, and has funded hundreds of projects
since then, therefore the data sought would span over two decades. The EVOSTC
required publication of data within one year of data collection for all of
their grants but did not specify or provide a publication platform. Grants
funded a variety of disciplines with mainly a marine focus and grantees
included government agencies, private consulting firms and non-governmental
organizations, and Alaska native groups. We wanted to know for how many of
these projects we could acquire data, if there were trends in data reporting
based on data or grantee characteristics and if data were not procured, why we
were unsuccessful. The EVOSTC did make an effort to collect these data in the
mid 1990s but the success of this effort is unknown as the content of this
collection has since been lost. <br></div><div><div><br></div><br></div><div><br></div><div><br></div>